{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f92757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 4.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (4.64.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (3.19.4)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (1.23.0)\n",
      "Requirement already satisfied: six in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 5.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: etils[epath] in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (0.6.0)\n",
      "Requirement already satisfied: termcolor in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: absl-py in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.10)\n",
      "Requirement already satisfied: importlib_resources in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets) (5.8.0)\n",
      "Requirement already satisfied: zipp in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets) (3.8.0)\n",
      "Requirement already satisfied: typing_extensions in /home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets) (4.3.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=9fbdbe58a61d5f598586ab18533ceca309b228da08cfea294ee6ce706c76381a\n",
      "  Stored in directory: /home/h3r0/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built promise\n",
      "Installing collected packages: googleapis-common-protos, toml, tensorflow-metadata, promise, dill, tensorflow-datasets\n",
      "Successfully installed dill-0.3.5.1 googleapis-common-protos-1.56.3 promise-2.3 tensorflow-datasets-4.6.0 tensorflow-metadata-1.9.0 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0388ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "# if 'TPU_DRIVER_MODE' not in globals():\n",
    "#   url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver_nightly'\n",
    "#   resp = requests.post(url)\n",
    "#   TPU_DRIVER_MODE = 1\n",
    "# The following is required to use TPU Driver as JAX's backend.\n",
    "import os\n",
    "from jax.config import config\n",
    "# config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
    "# config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
    "# print(config.FLAGS.jax_backend_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349aa55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def shard(xs):\n",
    "    return jax.tree_map(\n",
    "        lambda x: x.reshape((jax.device_count(), -1) + x.shape[1:]), xs)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    training: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, z):\n",
    "        x = nn.ConvTranspose(features=64*8, kernel_size=(4, 4),\n",
    "                             strides=(1, 1), padding='VALID', use_bias=False)(z)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        x = nn.ConvTranspose(features=64*4, kernel_size=(4, 4),\n",
    "                             strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        x = nn.ConvTranspose(features=64*2, kernel_size=(4, 4),\n",
    "                             strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        x = nn.ConvTranspose(features=64, kernel_size=(\n",
    "            4, 4), strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        x = nn.ConvTranspose(features=1, kernel_size=(\n",
    "            4, 4), strides=(1, 1), padding='SAME', use_bias=False)(x)\n",
    "        return jnp.tanh(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    training: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=64, kernel_size=(\n",
    "            4, 4), strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "        x = nn.Conv(features=64*2, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "        x = nn.Conv(features=64*4, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "        x = nn.Conv(features=64*8, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='SAME', use_bias=False)(x)\n",
    "        x = nn.BatchNorm(\n",
    "            use_running_average=not self.training, momentum=0.9)(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "        x = nn.Conv(features=1, kernel_size=(\n",
    "            1, 1), strides=(4, 4), padding='VALID', use_bias=False)(x)\n",
    "        x = jnp.reshape(x, [x.shape[0], -1])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "@jax.vmap\n",
    "def bce_logits_loss(logit, label):\n",
    "    return jnp.maximum(logit, 0) - logit * label + jnp.log(1 + jnp.exp(-jnp.abs(logit)))\n",
    "\n",
    "\n",
    "def loss_g(params_g, params_d, batch, rng, variables_g, variables_d):\n",
    "    z = jax.random.normal(rng, shape=(batch.shape[0], 1, 1, 100))\n",
    "\n",
    "    fake_batch, variables_g = Generator(training=True).apply(\n",
    "        {'params': params_g, 'batch_stats': variables_g['batch_stats']}, z, mutable=['batch_stats'])\n",
    "\n",
    "    fake_logits, variables_d = Discriminator(training=True).apply(\n",
    "        {'params': params_d, 'batch_stats': variables_d['batch_stats']}, fake_batch, mutable=['batch_stats'])\n",
    "\n",
    "    real_labels = jnp.ones((batch.shape[0],), dtype=jnp.int32)\n",
    "    return jnp.mean(bce_logits_loss(fake_logits, real_labels)), (variables_g, variables_d)\n",
    "\n",
    "\n",
    "def loss_d(params_d, params_g, batch, rng, variables_g, variables_d):\n",
    "    z = jax.random.normal(rng, shape=(batch.shape[0], 1, 1, 100))\n",
    "\n",
    "    fake_batch, variables_g = Generator(training=True).apply(\n",
    "        {'params': params_g, 'batch_stats': variables_g['batch_stats']}, z, mutable=['batch_stats'])\n",
    "\n",
    "    real_logits, variables_d = Discriminator(training=True).apply(\n",
    "        {'params': params_d, 'batch_stats': variables_d['batch_stats']}, batch, mutable=['batch_stats'])\n",
    "    fake_logits, variables_d = Discriminator(training=True).apply(\n",
    "        {'params': params_d, 'batch_stats': variables_d['batch_stats']}, fake_batch, mutable=['batch_stats'])\n",
    "\n",
    "    real_labels = jnp.ones((batch.shape[0],), dtype=jnp.int32)\n",
    "    real_loss = bce_logits_loss(real_logits, real_labels)\n",
    "\n",
    "    fake_labels = jnp.zeros((batch.shape[0],), dtype=jnp.int32)\n",
    "    fake_loss = bce_logits_loss(fake_logits, fake_labels)\n",
    "\n",
    "    return jnp.mean(real_loss + fake_loss), (variables_g, variables_d)\n",
    "\n",
    "\n",
    "@partial(jax.pmap, axis_name='batch')\n",
    "def train_step(rng, variables_g, variables_d, optimizer_g, optimizer_d, batch):\n",
    "    rng, rng_g, rng_d = jax.random.split(rng, 3)\n",
    "\n",
    "    (g_loss, (variables_g, variables_d)), grad_g = jax.value_and_grad(loss_g, has_aux=True)(\n",
    "        optimizer_g.target, optimizer_d.target, batch, rng_g, variables_g, variables_d)\n",
    "    g_loss = jax.lax.pmean(g_loss, axis_name='batch')\n",
    "    grad_g = jax.lax.pmean(grad_g, axis_name='batch')\n",
    "\n",
    "    optimizer_g = optimizer_g.apply_gradient(grad_g)\n",
    "\n",
    "    (d_loss, (variables_g, variables_d)), grad_d = jax.value_and_grad(loss_d, has_aux=True)(\n",
    "        optimizer_d.target, optimizer_g.target, batch, rng_d, variables_g, variables_d)\n",
    "\n",
    "    d_loss = jax.lax.pmean(d_loss, axis_name='batch')\n",
    "    grad_d = jax.lax.pmean(grad_d, axis_name='batch')\n",
    "\n",
    "    optimizer_d = optimizer_d.apply_gradient(grad_d)\n",
    "\n",
    "    return rng, variables_g, variables_d, optimizer_g, optimizer_d, d_loss, g_loss\n",
    "\n",
    "\n",
    "def make_dataset(batch_size, seed=1):\n",
    "    mnist = tfds.load(\"mnist\")\n",
    "\n",
    "    def _preprocess(sample):\n",
    "        image = tf.image.convert_image_dtype(sample[\"image\"], tf.float32)\n",
    "        image = tf.image.resize(image, (32, 32))\n",
    "        return 2.0 * image - 1.0\n",
    "\n",
    "    ds = mnist[\"train\"]\n",
    "    ds = ds.map(map_func=_preprocess,\n",
    "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.shuffle(10 * batch_size, seed=seed).repeat().batch(batch_size)\n",
    "    return iter(tfds.as_numpy(ds))\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset = make_dataset(batch_size=256)\n",
    "\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    rng, rng_g, rng_d = jax.random.split(rng, 3)\n",
    "\n",
    "    init_batch_g = jnp.ones((1, 1, 1, 100), jnp.float32)\n",
    "    variables_g = Generator(training=True).init(rng_g, init_batch_g)\n",
    "\n",
    "    init_batch_d = jnp.ones((1, 32, 32, 1), jnp.float32)\n",
    "    variables_d = Discriminator(training=True).init(rng_d, init_batch_d)\n",
    "\n",
    "    optimizer_g = flax.optim.Adam(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9).create(variables_g[\"params\"])\n",
    "    optimizer_g = flax.jax_utils.replicate(optimizer_g)\n",
    "\n",
    "    optimizer_d = flax.optim.Adam(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9).create(variables_d[\"params\"])\n",
    "    optimizer_d = flax.jax_utils.replicate(optimizer_d)\n",
    "\n",
    "    variables_g = flax.jax_utils.replicate(variables_g)\n",
    "    variables_d = flax.jax_utils.replicate(variables_d)\n",
    "\n",
    "    rngs = jax.random.split(rng, num=jax.local_device_count())\n",
    "\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "\n",
    "    for i in tqdm(range(2000)):\n",
    "        img_a = shard(next(dataset))\n",
    "\n",
    "        rngs, variables_g, variables_d, optimizer_g, optimizer_d, d_loss, g_loss = train_step(\n",
    "            rngs, variables_g, variables_d, optimizer_g, optimizer_d, img_a)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            g_losses.append(float(jnp.mean(g_loss)))\n",
    "            d_losses.append(float(jnp.mean(d_loss)))\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                rng, rng_sample = jax.random.split(rng)\n",
    "                z = jax.random.normal(rng_sample, shape=(1, 1, 1, 100))\n",
    "\n",
    "                temp_params_g = flax.jax_utils.unreplicate(\n",
    "                    optimizer_g.target)\n",
    "                temp_variables_g = flax.jax_utils.unreplicate(variables_g)\n",
    "\n",
    "                samples = Generator(training=False).apply(\n",
    "                    {'params': temp_params_g, 'batch_stats': temp_variables_g['batch_stats']}, z, mutable=False)\n",
    "\n",
    "                img = jnp.reshape((samples + 1) / 2, [32, 32])\n",
    "                plt.imshow(img, cmap='gray')\n",
    "                plt.show()\n",
    "    return g_losses, d_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23d1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f635ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 19:22:26.846455: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ~/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a980b0d1aebe4be0b9bce36f4f63e089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to ~/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 19:22:32.857811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.857963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-07 19:22:32.858589: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages/flax/optim/base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
      "  warnings.warn(\n",
      "/home/h3r0/anaconda3/envs/jax/lib/python3.9/site-packages/flax/optim/base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
      "  warnings.warn(\n",
      "  0%|                                                          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                             | 26/2000 [24:44<32:42:16, 59.64s/it]"
     ]
    }
   ],
   "source": [
    "g_losses, d_losses = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses, label='g_loss')\n",
    "plt.plot(d_losses, label='d_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db59a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
